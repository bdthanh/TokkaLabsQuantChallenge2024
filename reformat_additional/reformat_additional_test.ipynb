{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to process additional data\n",
    "\n",
    "I downloaded additional data from Binance website for the missing period between Aug 2023 to end of Feb 2024. Therefore, I need to reformat the data to the same format with train.csv for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ADDITIONAL_FOLDER = r'C:\\Users\\e0817820\\Desktop\\tokka\\data\\additional_test'\n",
    "RAW_FOLDER = r'C:\\Users\\e0817820\\Desktop\\tokka\\data\\raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file():\n",
    "    for file in os.listdir(ADDITIONAL_FOLDER):\n",
    "        if file.endswith(\".zip\"):\n",
    "            file_path = os.path.join(ADDITIONAL_FOLDER, file)\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(ADDITIONAL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cryptocurrencies = ['AVAX', 'ADA', 'SOL', 'BNB', 'TRX', 'DOGE', 'LINK', 'XRP', 'BTC', 'ETH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'count', 'taker_buy_volume', 'taker_buy_quote_volume', 'ignore', 'symbol', 'log_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    combine_df = pd.DataFrame()\n",
    "    for currency in list_cryptocurrencies:\n",
    "        combine_curr_df = pd.DataFrame()\n",
    "        for file in os.listdir(ADDITIONAL_FOLDER):\n",
    "            if file.endswith(\".csv\") and 'combine_df' not in file and currency in file:\n",
    "                print(f'Processing: {file}')\n",
    "                file_path = os.path.join(ADDITIONAL_FOLDER, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                df.columns = columns[:12]\n",
    "                df['symbol'] = [currency for i in range(len(df))]\n",
    "                combine_curr_df = pd.concat([combine_curr_df.reset_index(drop=True), df], ignore_index=True)\n",
    "                combine_curr_df.columns = columns[:13]\n",
    "        combine_curr_df['log_return'] = np.log(combine_curr_df['close'].shift(-10) / combine_curr_df['close'])\n",
    "        combine_df = pd.concat([combine_df, combine_curr_df], ignore_index=True)\n",
    "    combine_df.columns = columns\n",
    "    combine_df = combine_df.dropna()\n",
    "    combine_df.to_csv(os.path.join(ADDITIONAL_FOLDER, 'combine_df_test.csv'))    \n",
    "    print(combine_df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: AVAXUSDT-1m-2024-02-29.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-01.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-02.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-03.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-04.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-05.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-06.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-07.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-08.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-09.csv\n",
      "Processing: AVAXUSDT-1m-2024-03-10.csv\n",
      "Processing: ADAUSDT-1m-2024-02-29.csv\n",
      "Processing: ADAUSDT-1m-2024-03-01.csv\n",
      "Processing: ADAUSDT-1m-2024-03-02.csv\n",
      "Processing: ADAUSDT-1m-2024-03-03.csv\n",
      "Processing: ADAUSDT-1m-2024-03-04.csv\n",
      "Processing: ADAUSDT-1m-2024-03-05.csv\n",
      "Processing: ADAUSDT-1m-2024-03-06.csv\n",
      "Processing: ADAUSDT-1m-2024-03-07.csv\n",
      "Processing: ADAUSDT-1m-2024-03-08.csv\n",
      "Processing: ADAUSDT-1m-2024-03-09.csv\n",
      "Processing: ADAUSDT-1m-2024-03-10.csv\n",
      "Processing: SOLUSDT-1m-2024-02-29.csv\n",
      "Processing: SOLUSDT-1m-2024-03-01.csv\n",
      "Processing: SOLUSDT-1m-2024-03-02.csv\n",
      "Processing: SOLUSDT-1m-2024-03-03.csv\n",
      "Processing: SOLUSDT-1m-2024-03-04.csv\n",
      "Processing: SOLUSDT-1m-2024-03-05.csv\n",
      "Processing: SOLUSDT-1m-2024-03-06.csv\n",
      "Processing: SOLUSDT-1m-2024-03-07.csv\n",
      "Processing: SOLUSDT-1m-2024-03-08.csv\n",
      "Processing: SOLUSDT-1m-2024-03-09.csv\n",
      "Processing: SOLUSDT-1m-2024-03-10.csv\n",
      "Processing: BNBUSDT-1m-2024-02-29.csv\n",
      "Processing: BNBUSDT-1m-2024-03-01.csv\n",
      "Processing: BNBUSDT-1m-2024-03-02.csv\n",
      "Processing: BNBUSDT-1m-2024-03-03.csv\n",
      "Processing: BNBUSDT-1m-2024-03-04.csv\n",
      "Processing: BNBUSDT-1m-2024-03-05.csv\n",
      "Processing: BNBUSDT-1m-2024-03-06.csv\n",
      "Processing: BNBUSDT-1m-2024-03-07.csv\n",
      "Processing: BNBUSDT-1m-2024-03-08.csv\n",
      "Processing: BNBUSDT-1m-2024-03-09.csv\n",
      "Processing: BNBUSDT-1m-2024-03-10.csv\n",
      "Processing: TRXUSDT-1m-2024-02-29.csv\n",
      "Processing: TRXUSDT-1m-2024-03-01.csv\n",
      "Processing: TRXUSDT-1m-2024-03-02.csv\n",
      "Processing: TRXUSDT-1m-2024-03-03.csv\n",
      "Processing: TRXUSDT-1m-2024-03-04.csv\n",
      "Processing: TRXUSDT-1m-2024-03-05.csv\n",
      "Processing: TRXUSDT-1m-2024-03-06.csv\n",
      "Processing: TRXUSDT-1m-2024-03-07.csv\n",
      "Processing: TRXUSDT-1m-2024-03-08.csv\n",
      "Processing: TRXUSDT-1m-2024-03-09.csv\n",
      "Processing: TRXUSDT-1m-2024-03-10.csv\n",
      "Processing: DOGEUSDT-1m-2024-02-29.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-01.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-02.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-03.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-04.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-05.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-06.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-07.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-08.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-09.csv\n",
      "Processing: DOGEUSDT-1m-2024-03-10.csv\n",
      "Processing: LINKUSDT-1m-2024-02-29.csv\n",
      "Processing: LINKUSDT-1m-2024-03-01.csv\n",
      "Processing: LINKUSDT-1m-2024-03-02.csv\n",
      "Processing: LINKUSDT-1m-2024-03-03.csv\n",
      "Processing: LINKUSDT-1m-2024-03-04.csv\n",
      "Processing: LINKUSDT-1m-2024-03-05.csv\n",
      "Processing: LINKUSDT-1m-2024-03-06.csv\n",
      "Processing: LINKUSDT-1m-2024-03-07.csv\n",
      "Processing: LINKUSDT-1m-2024-03-08.csv\n",
      "Processing: LINKUSDT-1m-2024-03-09.csv\n",
      "Processing: LINKUSDT-1m-2024-03-10.csv\n",
      "Processing: XRPUSDT-1m-2024-02-29.csv\n",
      "Processing: XRPUSDT-1m-2024-03-01.csv\n",
      "Processing: XRPUSDT-1m-2024-03-02.csv\n",
      "Processing: XRPUSDT-1m-2024-03-03.csv\n",
      "Processing: XRPUSDT-1m-2024-03-04.csv\n",
      "Processing: XRPUSDT-1m-2024-03-05.csv\n",
      "Processing: XRPUSDT-1m-2024-03-06.csv\n",
      "Processing: XRPUSDT-1m-2024-03-07.csv\n",
      "Processing: XRPUSDT-1m-2024-03-08.csv\n",
      "Processing: XRPUSDT-1m-2024-03-09.csv\n",
      "Processing: XRPUSDT-1m-2024-03-10.csv\n",
      "Processing: BTCUSDT-1m-2024-02-29.csv\n",
      "Processing: BTCUSDT-1m-2024-03-01.csv\n",
      "Processing: BTCUSDT-1m-2024-03-02.csv\n",
      "Processing: BTCUSDT-1m-2024-03-03.csv\n",
      "Processing: BTCUSDT-1m-2024-03-04.csv\n",
      "Processing: BTCUSDT-1m-2024-03-05.csv\n",
      "Processing: BTCUSDT-1m-2024-03-06.csv\n",
      "Processing: BTCUSDT-1m-2024-03-07.csv\n",
      "Processing: BTCUSDT-1m-2024-03-08.csv\n",
      "Processing: BTCUSDT-1m-2024-03-09.csv\n",
      "Processing: BTCUSDT-1m-2024-03-10.csv\n",
      "Processing: ETHUSDT-1m-2024-02-29.csv\n",
      "Processing: ETHUSDT-1m-2024-03-01.csv\n",
      "Processing: ETHUSDT-1m-2024-03-02.csv\n",
      "Processing: ETHUSDT-1m-2024-03-03.csv\n",
      "Processing: ETHUSDT-1m-2024-03-04.csv\n",
      "Processing: ETHUSDT-1m-2024-03-05.csv\n",
      "Processing: ETHUSDT-1m-2024-03-06.csv\n",
      "Processing: ETHUSDT-1m-2024-03-07.csv\n",
      "Processing: ETHUSDT-1m-2024-03-08.csv\n",
      "Processing: ETHUSDT-1m-2024-03-09.csv\n",
      "Processing: ETHUSDT-1m-2024-03-10.csv\n",
      "(158190, 14)\n"
     ]
    }
   ],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
      "       'close_time', 'quote_volume', 'count', 'taker_buy_volume',\n",
      "       'taker_buy_quote_volume', 'ignore', 'symbol', 'log_return'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(ADDITIONAL_FOLDER, 'combine_df_test.csv'))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['id', 'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "       'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_volume',\n",
    "       'taker_sell_volume', 'ignore', 'symbol', 'log_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['close_time', 'ignore', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158190, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate log return of the asset over next 10 minutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_timestamp = 1709222400000\n",
    "upper_timestamp = 1710086400000\n",
    "df = df[df['timestamp'] >= lower_timestamp]\n",
    "df = df[df['timestamp'] <= upper_timestamp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(ADDITIONAL_FOLDER, 'add_test.csv'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143910, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
